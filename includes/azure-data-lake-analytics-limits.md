---
author: rothja
ms.service: data-lake-analytics
ms.topic: include
ms.date: 11/09/2018    
ms.author: jroth
---
Azure Data Lake Analytics makes the complex task of managing distributed infrastructure and complex code easy. It dynamically provisions resources, and you can use it to do analytics on exabytes of data. When the job completes, it winds down resources automatically. You pay only for the processing power that was used. As you increase or decrease the size of data stored or the amount of compute used, you don't have to rewrite code. To raise the default limits for your subscription, contact support.

| **Resource** | **Limit** | **Comments** |
| --- | --- | --- |
| Maximum number of concurrent jobs |20 | |
| Maximum number of analytics units (AUs) per account |250 | Use any combination of up to a maximum of 250 AUs across 20 jobs. To increase this limit, contact Microsoft Support. |
| Maximum script size for job submission | 3 MB | |
| Maximum number of Data Lake Analytics accounts per region per subscription | 5 | To increase this limit, contact Microsoft Support. |
