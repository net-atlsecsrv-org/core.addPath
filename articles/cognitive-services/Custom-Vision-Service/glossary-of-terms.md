---
title: Glossary of Terms - Custom Vision Service
titlesuffix: Azure Cognitive Services
description: Glossary of Terms for Custom Vision Service.
services: cognitive-services
author: anrothMSFT
manager: nitinme

ms.service: cognitive-services
ms.subservice: custom-vision
ms.topic: conceptual
ms.date: 04/03/2019
ms.author: anroth
---
# Glossary of terms for Custom Vision Service

The following are some terms commonly used in Custom Vision Service:

## Classifier

A classifier is a model you build using Custom Vision Service, by using a few training images. Once you have finished training a new classifier, you receive an evaluation endpoint (HTTPS) you can add to your app. Each classifier you build is in its own project, and you can view all projects once you have signed in.

## Domain

When you create a project, you select a "domain" for that project. The domain optimizes a classifier for a specific type of object in your images. For example, if your scenario is to classify between images of apple pie versus images of carrot cake, then select the "Food" domain. If you are unsure of which domain to choose, then select "Generic" domain.

- **The Food domain.** Optimized for dishes you would see on a restaurant menu. It was not optimized for recognizing individual fruit or vegetables. If you want to classify photographs of individual fruits or vegetables, use the Generic domain for that purpose.
- **The Landmark domain.** Optimized for recognizable landmarks, both natural and artificial. This domain works best when the landmark is clearly visible in the photograph, even if the landmark is slightly obstructed by a group of people posing in front of it.
- **The Retail domain.** Optimized for classifying images in a shopping catalog or shopping website. If you want high precision when classifying dresses, pants, shirts, etc., then use the Retail domain.
- **The General domain.** Well suited for a broad variety of image classification tasks.

The models generated by **compact domains** can be exported with the iteration export functionality. They are optimized for the constraints of real-time classification on mobile devices. Classifiers built with a compact domain may be slightly less accurate a standard domain with the same amount of training data. The tradeoff is that they are small enough to be run locally in near real time. 

## Evaluation

Once you have trained your classifier, you can submit any image for evaluation by using the auto-generated https endpoint. Your classifier returns a set of predicted tags, in order of confidence.

## Iteration

Every time you Train or re-train your classifier, you create a new iteration of your model. We keep several past iterations to allow you to compare your progress over time. You can delete any iteration you no longer find useful. Remember that deleting an iteration is permanent, and you also delete any images or changes that were unique to that iteration. 

## Precision

When you classify an image, how likely is your classifier to correctly classify the image? Out of all images used to train the classifier (dogs and ponies), what percent did the model get correct? 99 correct tags out of 100 images gives a Precision of 99%.

## Predictions

As your classifier accepts new images to classify, it stores the images for you. You can use these images to improve the precision of your classifier by correctly tagging the mis-predicted images. You can then use these new images to re-train your classifier.

## Recall

Out of all images that should have been classified correctly, how many did your classifier identify correctly? A Recall of 100% would mean, if there were 38 dog images in the images used to train the classifier, 38 dogs were found by the classifier.

## Settings

There are two types of settings, Project-Level settings and User-Level settings.

- Project-Level settings:
  
  Project-level settings apply to a project or classifier. They include:

   - Project-domain
   - Project Name
   - Project Description
   - Usage:
      - Number of training images
      - Number of tags created
      - Number of iterations created

- User-Level settings: 
   - Subscription Keys: one for Training, one for Evaluation/Prediction.
   - Usage:
      - Number of projects created
      - Number of Evaluation/Prediction API calls made.

## Tags

Use tags to label the objects in your training images. If you are creating a classifier to identify dogs and ponies, you would put a "dog" tag on images that contain dogs, a "pony" tag on images that contain ponies, and both a "dog" and a "pony" tag on images that contain both a dog and a pony.

## Training image

To create a high precision classifier, Custom Vision Service needs several training images. A training image is a photograph of the image you want Custom Vision Service to classify. For example, to classify oranges, you would need to upload several images of oranges to Custom Vision Service to allow the service to create a classifier that can recognize oranges. We recommend at least 30 images per tag.

## Workspace

Your workspace contains all your training images, and it reflects all changes from your most recent iteration such as removed or added images. When you Train your classifier, you create a new iteration of your classifier, by using the images present in your Workspace.