---
title:  "Export Data: Module Reference"
titleSuffix: Azure Machine Learning service
description: Learn how to use the Export Data module in Azure Machine Learning service to save results, intermediate data, and working data from your pipelines into cloud storage destinations outside Azure Machine Learning.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference

author: xiaoharper
ms.author: zhanxia
ms.date: 05/02/2019
---
# Export Data module

This article describes a module of the visual interface (preview) for Azure Machine Learning service.

Use this module to save results, intermediate data, and working data from your pipelines into cloud storage destinations outside Azure Machine Learning.

This module supports exporting or saving your data to the following cloud data services:


- **Export to Azure Blob Storage**: Saves data to the Blob service in Azure. Data in the Blob service can be shared publicly or saved in secured application data stores.

  
## How to configure Export Data

1. Add the **Export Data** module to your pipeline in the interface. You can find this module in the **Input and Output** category.

2. Connect **Export Data** to the module that contains the data you want to export.

3. Double-click **Export Data** to open the **Properties** pane.

4. For **Data destination**, select the type of cloud storage where you'll save your data. If you make any changes to this option, all other properties are reset. So be sure to choose this option first!

5. Provide an account name and authentication method required to access the specified storage account.

    **Export to Azure Blob Storage** is the only option in private preview. Below shows how to set the module.
    1. The Azure blob service is for storing large amounts of data, including binary data. There are two types of blob storage: public blobs, and blobs that require login credentials.

    2. For **Authentication type**, choose **Public (SAS)** if you know that the storage supports access via a SAS URL.

          A SAS URL is a special type of URL that can be  generated by using an Azure storage utility, and is available for only a limited time.  It contains all the information that is needed for authentication and download.

        For **URI**, type or paste the full URI that defines the account and the public blob.

        For file format, CSV and TSV are supported.

    3. For private accounts, choose **Account**, and provide the account name and the account key, so that the pipeline can write to the storage account.

         - **Account name**: Type or paste the name of the account where you want to save the data. For example, if the full URL of the storage account is `http://myshared.blob.core.windows.net`, you would type `myshared`.

        - **Account key**: Paste the storage access key that is associated with the account.

        -  **Path to container, directory, or blob**: Type the name of the blob where the exported data will be stored. For example, to save the results of your pipeline to a new blob named **results01.csv** in the container **predictions** in an account named **mymldata**, the full URL for the blob would be `http://mymldata.blob.core.windows.net/predictions/results01.csv`.

            Therefore, in the field  **Path to container, directory, or blob**, you would specify the container and blob name as follows: `predictions/results01.csv`

        - If you specify the name of a blob that does not already exist, Azure creates the blob for you.

       -  When writing to an existing blob, you can specify that current contents of the blob be overwritten by setting the property, **Azure blob storage write mode**. By default, this property is set to **Error**, meaning that an error is raised whenever an existing blob file of the same name is found.


    4. For **File format for blob file**, select the format in which data should be stored.

        - **CSV**: Comma-separated values (CSV) are the default storage format. To export column headings together with the data, select the option, **Write blob header row**.  For more information about the comma- delimited format used in Azure Machine Learning, see [Convert to CSV](./convert-to-csv.md).

        - **TSV**: Tab-separated values (TSV) format is compatible with many machine learning tools. To export column headings together with the data, select the option, **Write blob header row**.  

 
    5. **Use cached results**: Select this option if you want to avoid rewriting the results to the blob file each time you run the pipeline. If there are no other changes to module parameters, the pipeline writes the results only the first time the module is run, or when there are changes to the data.

    6. Run the pipeline.

## Next steps

See the [set of modules available](module-reference.md) to Azure Machine Learning service. 